{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.6 64-bit ('tensor_gpu_38': venv)"
  },
  "interpreter": {
   "hash": "8aba9d492c0a4bef6a645f552c7b10b957d4aabb43f48e824b5c35f92cd434de"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pre_process.load_sleep_data import LoadSleepData\n",
    "from pre_process.pre_process import PreProcess\n",
    "import numpy as np\n",
    "import sys, os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.decomposition import PCA\n",
    "import sys\n",
    "from sklearn.manifold import TSNE\n",
    "from collections import Counter\n",
    "import tensorflow as tf\n",
    "from nn.losses import EDLLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\taiki\\\\git\\\\sleep_study'"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "*** すべての被験者を読み込みます（load_dataの引数:nameは無視します） ***\n",
      "D:\\takadamalab\\sleep_study\\datas\\pre_processed_data\\H_Li_20210201-055748.savを読み込んでいます...\n",
      "D:\\takadamalab\\sleep_study\\datas\\pre_processed_data\\H_Murakami_20210201-055748.savを読み込んでいます...\n",
      "D:\\takadamalab\\sleep_study\\datas\\pre_processed_data\\H_Yamamoto_20210201-055748.savを読み込んでいます...\n",
      "D:\\takadamalab\\sleep_study\\datas\\pre_processed_data\\H_Kumazawa_20210201-055748.savを読み込んでいます...\n",
      "D:\\takadamalab\\sleep_study\\datas\\pre_processed_data\\H_Hayashi_20210201-055748.savを読み込んでいます...\n",
      "D:\\takadamalab\\sleep_study\\datas\\pre_processed_data\\H_Kumazawa_F_20210201-055748.savを読み込んでいます...\n",
      "D:\\takadamalab\\sleep_study\\datas\\pre_processed_data\\H_Takadama_20210201-055748.savを読み込んでいます...\n",
      "D:\\takadamalab\\sleep_study\\datas\\pre_processed_data\\H_Hiromoto_20210201-055748.savを読み込んでいます...\n",
      "D:\\takadamalab\\sleep_study\\datas\\pre_processed_data\\H_Kashiwazaki_20210201-055748.savを読み込んでいます...\n",
      "訓練データのサイズを揃えます\n",
      "訓練データの各睡眠段階（補正前） Counter({2: 3340, 4: 1184, 5: 499, 3: 395, 1: 181, None: 9})\n",
      "訓練データの各睡眠段階（補正後） {1: 1000, 2: 1000, 3: 1000, 4: 1000, 5: 1000}\n",
      "- 訓練データをシャッフルします\n",
      "- max正規化を行います\n",
      "- noneの処理を行います\n",
      "- チャンネル方向に軸を追加します\n",
      "*** 全ての前処理後（one-hotを除く）の訓練データセット（確認用） *** \n",
      " Counter({1: 1000, 0: 1000, 3: 1000, 4: 1000, 2: 1000})\n"
     ]
    }
   ],
   "source": [
    "load_sleep_data = LoadSleepData(data_type=\"spectrum\"\")\n",
    "pre_process = PreProcess(load_sleep_data)\n",
    "datas = load_sleep_data.load_data(load_all=True)\n",
    "(train, test) = pre_process.split_train_test_from_records(datas,\n",
    "                                                          test_id=0,\n",
    "                                                          pse_data=False)\n",
    "(x_train, y_train), (_, _) = pre_process.make_dataset(train=train, \n",
    "                                                      test=test, \n",
    "                                                      is_storchastic=False,\n",
    "                                                      to_one_hot_vector=False,\n",
    "                                                      pse_data=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "Unable to restore custom object of type _tf_keras_metric currently. Please make sure that the layer implements `get_config`and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-d1a6d6b85cab>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mdate_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"20210601-050450\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"sleep\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"models\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"H_Li\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdate_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m\"EDLLoss\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mEDLLoss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mannealing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\taiki\\.venv\\tensor_gpu_38\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\save.py\u001b[0m in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[0;32m    210\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m         \u001b[0mloader_impl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse_saved_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 212\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msaved_model_load\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    213\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m   raise IOError(\n",
      "\u001b[1;32mc:\\Users\\taiki\\.venv\\tensor_gpu_38\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\saved_model\\load.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(path, compile, options)\u001b[0m\n\u001b[0;32m    136\u001b[0m   \u001b[1;31m# Recreate layers and metrics using the info stored in the metadata.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m   \u001b[0mkeras_loader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKerasObjectLoader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobject_graph_def\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 138\u001b[1;33m   \u001b[0mkeras_loader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_layers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    139\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m   \u001b[1;31m# Generate a dictionary of all loaded nodes.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\taiki\\.venv\\tensor_gpu_38\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\saved_model\\load.py\u001b[0m in \u001b[0;36mload_layers\u001b[1;34m(self, compile)\u001b[0m\n\u001b[0;32m    378\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mnode_metadata\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmetric_list\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    379\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 380\u001b[1;33m         self.loaded_nodes[node_metadata.node_id] = self._load_layer(\n\u001b[0m\u001b[0;32m    381\u001b[0m             \u001b[0mnode_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnode_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0midentifier\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    382\u001b[0m             node_metadata.metadata)\n",
      "\u001b[1;32mc:\\Users\\taiki\\.venv\\tensor_gpu_38\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\saved_model\\load.py\u001b[0m in \u001b[0;36m_load_layer\u001b[1;34m(self, node_id, identifier, metadata)\u001b[0m\n\u001b[0;32m    417\u001b[0m     \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msetter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_revive_from_config\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midentifier\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    418\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mobj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 419\u001b[1;33m       \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msetter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrevive_custom_object\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midentifier\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    420\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    421\u001b[0m     \u001b[1;31m# Add an attribute that stores the extra functions/objects saved in the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\taiki\\.venv\\tensor_gpu_38\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\saved_model\\load.py\u001b[0m in \u001b[0;36mrevive_custom_object\u001b[1;34m(identifier, metadata)\u001b[0m\n\u001b[0;32m    931\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mrevived_cls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_init_from_metadata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 933\u001b[1;33m     raise ValueError('Unable to restore custom object of type {} currently. '\n\u001b[0m\u001b[0;32m    934\u001b[0m                      \u001b[1;34m'Please make sure that the layer implements `get_config`'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    935\u001b[0m                      \u001b[1;34m'and `from_config` when saving. In addition, please use '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Unable to restore custom object of type _tf_keras_metric currently. Please make sure that the layer implements `get_config`and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`."
     ]
    }
   ],
   "source": [
    "# モデルを25次元の空間に出力\n",
    "date_id = \"20210601-050450\"\n",
    "path = os.path.join(os.environ[\"sleep\"], \"models\", \"H_Li\", date_id)\n",
    "model = tf.keras.models.load_model(path, custom_objects={\"EDLLoss\":EDLLoss(K=5,annealing=0.1)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pcaの実装\n",
    "def make_pca(data=None, target=None, pse_data=True, path=None, show_data=True,\n",
    "             test_id=0):\n",
    "    # 仮データを指定したときは読み込む\n",
    "    if pse_data:\n",
    "        assert data==None\n",
    "        digits = datasets.load_digits()\n",
    "        data = digits.data\n",
    "        target = digits.target\n",
    "    # pcaを実行\n",
    "    X_reduced = PCA(n_components=2).fit_transform(data)\n",
    "    # データを表示する際はデータを返さない\n",
    "    if show_data:\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(111)\n",
    "        mappable = ax.scatter(X_reduced[:, 0], X_reduced[:, 1], c=target)\n",
    "        plt.title(\"pca\", fontsize=20)\n",
    "        fig.colorbar(mappable, ax=ax)\n",
    "        plt.show()\n",
    "        plt.clf()\n",
    "    else:\n",
    "        return X_reduced, target\n",
    "make_pca(data=x_train, target=y_train, show_data=False, pse_data=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}
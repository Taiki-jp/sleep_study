{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: agg\n"
     ]
    }
   ],
   "source": [
    "%matplotlib\n",
    "import os\n",
    "import sys\n",
    "from IPython import display\n",
    "\n",
    "from rich import print\n",
    "from tensorflow.python.keras.metrics import accuracy\n",
    "\n",
    "from nn.wandb_classification_callback import WandbClassificationCallback\n",
    "\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "import datetime\n",
    "from collections import Counter\n",
    "from typing import Any, Dict, List\n",
    "\n",
    "import tensorflow as tf\n",
    "import wandb\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow_probability as tfp\n",
    "import PIL\n",
    "import imageio\n",
    "\n",
    "from data_analysis.py_color import PyColor\n",
    "from data_analysis.utils import Utils\n",
    "from nn.losses import EDLLoss\n",
    "from nn.model_base import VDANN\n",
    "\n",
    "# from nn.metrics import CategoricalTruePositives\n",
    "from pre_process.pre_process import PreProcess\n",
    "from pre_process.record import Record\n",
    "import random\n",
    "\n",
    "# from wandb.keras import WandbCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=200):\n",
    "    tf.random.set_seed(seed)\n",
    "    # optional\n",
    "    # for numpy.random\n",
    "    np.random.seed(seed)\n",
    "    # for built-in random\n",
    "    random.seed(seed)\n",
    "    # for hash seed\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_images(images):\n",
    "    images = images.reshape((images.shape[0], 28, 28, 1)) / 255.0\n",
    "    return np.where(images > 0.5, 1.0, 0.0).astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_save_images(model, epoch, test_sample):\n",
    "  mean, logvar = model.encode(test_sample)\n",
    "  z = model.reparameterize(mean, logvar)\n",
    "  predictions = model.sample(model, z)\n",
    "#   eps = tf.random.normal(shape=mean.shape)\n",
    "#   reparameterized = eps * tf.exp(logvar * 0.5) + mean\n",
    "#   predictions = model.decoder(reparameterized)\n",
    "  fig = plt.figure(figsize=(4, 4))\n",
    "\n",
    "  for i in range(predictions.shape[0]):\n",
    "    plt.subplot(4, 4, i + 1)\n",
    "    plt.imshow(predictions[i, :, :, 0], cmap='gray')\n",
    "    plt.axis('off')\n",
    "\n",
    "  # tight_layout minimizes the overlap between 2 sub-plots\n",
    "  plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 環境設定\n",
    "set_seed(0)\n",
    "CALC_DEVICE = \"gpu\"\n",
    "DEVICE_ID = \"0\" if CALC_DEVICE == \"gpu\" else \"-1\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = DEVICE_ID\n",
    "if os.environ[\"CUDA_VISIBLE_DEVICES\"] != \"-1\":\n",
    "    tf.keras.backend.set_floatx(\"float32\")\n",
    "    physical_devices = tf.config.list_physical_devices(\"GPU\")\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    # tf.config.run_functions_eagerly(True)\n",
    "else:\n",
    "    print(\"*** cpuで計算します ***\")\n",
    "    # なんか下のやつ使えなくなっている、、\n",
    "    tf.config.run_functions_eagerly(True)\n",
    "\n",
    "# ハイパーパラメータの設定\n",
    "TEST_RUN = False\n",
    "EPOCHS = 10\n",
    "HAS_ATTENTION = True\n",
    "PSE_DATA = False\n",
    "HAS_INCEPTION = True\n",
    "IS_PREVIOUS = False\n",
    "IS_NORMAL = True\n",
    "HAS_DROPOUT = True\n",
    "IS_ENN = False\n",
    "# FIXME: 多層化はとりあえずいらない\n",
    "IS_MUL_LAYER = True\n",
    "HAS_NREM2_BIAS = False\n",
    "HAS_REM_BIAS = False\n",
    "DROPOUT_RATE = 0.2\n",
    "BATCH_SIZE = 32\n",
    "N_CLASS = 5\n",
    "# KERNEL_SIZE = 512\n",
    "# KERNEL_SIZE = 256\n",
    "KERNEL_SIZE = 128\n",
    "STRIDE = 16\n",
    "# STRIDE = 16\n",
    "SAMPLE_SIZE = 10000\n",
    "DATA_TYPE = \"spectrogram\"\n",
    "FIT_POS = \"middle\"\n",
    "CLEANSING_TYPE = \"no_cleansing\"\n",
    "NORMAL_TAG = \"normal\" if IS_NORMAL else \"sas\"\n",
    "ATTENTION_TAG = \"attention\" if HAS_ATTENTION else \"no-attention\"\n",
    "PSE_DATA_TAG = \"psedata\" if PSE_DATA else \"sleepdata\"\n",
    "INCEPTION_TAG = \"inception\" if HAS_INCEPTION else \"no-inception\"\n",
    "WANDB_PROJECT = \"test\" if TEST_RUN else \"1215_test\"\n",
    "# WANDB_PROJECT = \"test\" if TEST_RUN else \"base_learning_20211109\"\n",
    "ENN_TAG = \"enn\" if IS_ENN else \"dnn\"\n",
    "INCEPTION_TAG += \"v2\" if IS_MUL_LAYER else \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# データセットの作成\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "x_train = preprocess_images(x_train)\n",
    "x_test = preprocess_images(x_test)\n",
    "train_size = 60000\n",
    "batch_size = 128\n",
    "test_size = 10000\n",
    "train_dataset = (\n",
    "    tf.data.Dataset.from_tensor_slices(x_train)\n",
    "    .shuffle(train_size)\n",
    "    .batch(batch_size)\n",
    ")\n",
    "test_dataset = (\n",
    "    tf.data.Dataset.from_tensor_slices(x_test)\n",
    "    .shuffle(test_size)\n",
    "    .batch(batch_size)\n",
    ")\n",
    "data_type = \"spectrogram\"\n",
    "shape = (28, 28, 1)\n",
    "inputs = tf.keras.Input(shape=shape)\n",
    "\n",
    "epochs = EPOCHS\n",
    "# set the dimensionality of the latent space to a plane for visualization later\n",
    "latent_dim = 4\n",
    "num_examples_to_generate = 16\n",
    "\n",
    "# keeping the random vector constant for generation (prediction) so\n",
    "# it will be easier to see the improvement.\n",
    "random_vector_for_generation = tf.random.normal(\n",
    "    shape=[num_examples_to_generate, latent_dim]\n",
    ")\n",
    "model = VDANN(\n",
    "    inputs=inputs,\n",
    "    gamma=1,\n",
    "    latent_dim=latent_dim,\n",
    "    alpha=0,\n",
    "    beta=0,\n",
    "    target_dim=5,\n",
    "    subject_dim=68,\n",
    "    has_inception=HAS_INCEPTION,\n",
    "    has_attention=HAS_ATTENTION,\n",
    ")\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick a sample of the test set for generating output images\n",
    "assert batch_size >= num_examples_to_generate\n",
    "for test_batch in test_dataset.take(1):\n",
    "  test_sample = test_batch[0:num_examples_to_generate, :, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_true_image(x):\n",
    "    fig = plt.figure(figsize=(4, 4))\n",
    "    for i in range(x.shape[0]):\n",
    "        plt.subplot(4, 4, i+1)\n",
    "        plt.imshow(x[i, :, :, 0], cmap='gray')\n",
    "        plt.axis('off')\n",
    "    plt.savefig(\"original_image_of_mine.png\")\n",
    "    plt.show()\n",
    "\n",
    "show_true_image(test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_and_save_images(model, 0, test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean, logvar = model.encode(test_sample)\n",
    "# eps = tf.random.normal(shape=(mean.shape))\n",
    "# reparameterized = eps * tf.exp(logvar * 0.5) + mean\n",
    "# predictions = model.decoder(reparameterized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure(figsize=(4, 4))\n",
    "# for i in range(predictions.shape[0]):\n",
    "#     plt.subplot(4, 4, i + 1)\n",
    "#     plt.imshow(predictions[i, :, :, 0], cmap='gray')\n",
    "#     plt.axis('off')\n",
    "# plt.show()\n",
    "\n",
    "# z = model.reparameterize(mean, logvar, latent_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_baes内にGPUの計算中にnumpyに渡すことが出来ないのでmainにlambda式用意\n",
    "tensor2numpy = lambda x: x.numpy()\n",
    "for epoch in range(epochs):\n",
    "    test_loss_metric = tf.keras.metrics.Mean()\n",
    "    # print(\"Start of epoch %d\" % (epoch,))\n",
    "\n",
    "    # Iterate over the batches of the dataset.\n",
    "    for step, x_batch_train in enumerate(train_dataset):\n",
    "        train_loss = model.train_step(x_batch_train)\n",
    "        # if step % 50 == 0:\n",
    "        #     print(\n",
    "        #         f\"train loss: (vae, sbj, tar) =  {tuple(map(tensor2numpy, train_loss))}\"\n",
    "        #     )\n",
    "    # train_metrics.reset_states()\n",
    "\n",
    "    for step, x_batch_test in enumerate(test_dataset):\n",
    "        test_loss = model.test_step(x_batch_test)\n",
    "        test_loss_metric(test_loss)\n",
    "    elbo = -test_loss_metric.result()\n",
    "    display.clear_output(wait=False)\n",
    "    # print(\n",
    "    #     f\"test loss: (vae, sbj, tar) = {tuple(map(tensor2numpy, test_loss))}\"\n",
    "    # )\n",
    "    print(f\"Epoch: {epoch}, Test set ELBO: {elbo}\")\n",
    "    # test_metrics.reset_states()\n",
    "    generate_and_save_images(model, epoch, test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image(epoch_no):\n",
    "  return PIL.Image.open('image_at_epoch_{:04d}.png'.format(epoch_no))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(display_image(epoch))\n",
    "plt.axis('off')  # Display images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "anim_file = 'cvae.gif'\n",
    "\n",
    "with imageio.get_writer(anim_file, mode='I') as writer:\n",
    "  filenames = glob.glob('image*.png')\n",
    "  filenames = sorted(filenames)\n",
    "  for filename in filenames:\n",
    "    image = imageio.imread(filename)\n",
    "    writer.append_data(image)\n",
    "  image = imageio.imread(filename)\n",
    "  writer.append_data(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_docs.vis.embed as embed\n",
    "embed.embed_file(anim_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 入力データを見てみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(test_sample[6], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_true_image(x):\n",
    "    fig = plt.figure(figsize=(4, 4))\n",
    "    for i in range(x.shape[0]):\n",
    "        plt.subplot(4, 4, i+1)\n",
    "        plt.imshow(x[i, :, :, 0], cmap='gray')\n",
    "        plt.axis('off')\n",
    "    plt.savefig(\"original_image.png\")\n",
    "    plt.show()\n",
    "\n",
    "show_true_image(test_sample)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f85485fd48dafec2c9ee44902fb5f75cf97c1bb769ea19212b2acde995ff45da"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
